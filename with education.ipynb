{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d372a06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, json, time, csv\n",
    "from plotly.io import write_html\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3f25f7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map(API_KEY, company_name, size):\n",
    "    \"\"\"\n",
    "    Purpose:\n",
    "    Calls API with API_KEY to return size amount of employees from company of company_name.\n",
    "    \n",
    "    Return: \n",
    "    CSV file named \"{company_name}{size}_employee.csv\" if a file of that name doesn't already exist. This is so costly\n",
    "    calls aren't repeated if we already have the dataset for them\n",
    "    A plotly plot of the addresses of employees from company_name and the company HQ address.\n",
    "    \n",
    "    Parameters: \n",
    "    API_KEY is the string of your API key with PDL\n",
    "    company_name is a string of the company's name\n",
    "    size is an int of how many employees you want retrieved max. If you want all available employees, use -1\"\"\"\n",
    "    \n",
    "    #basic test cases\n",
    "    if type(company_name) != str:\n",
    "        raise TypeError\n",
    "    if type(size) != int:\n",
    "        raise TypeError\n",
    "    if type(API_KEY) != str:\n",
    "        raise TypeError   \n",
    "    if len(API_KEY) < 5:\n",
    "        raise ValueError\n",
    "        \n",
    "    csv_filename = company_name + str(size) + \"_employees.csv\"\n",
    "    try:\n",
    "        df = pd.read_csv(csv_filename)\n",
    "    except (FileNotFoundError):\n",
    "        #the following is code from PDL's Query Builder https://www.peopledatalabs.com/main/query-builder\n",
    "        MAX_NUM_RECORDS = size\n",
    "\n",
    "    # NO CHANGES NEEDED BELOW HERE\n",
    "        PDL_URL = \"https://api.peopledatalabs.com/v5/person/search\"\n",
    "        request_header = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"X-api-key\": API_KEY\n",
    "        }\n",
    "        \n",
    "        ES_QUERY = {\n",
    "            \"query\": {\n",
    "                \"bool\": {\n",
    "                    \"must\": [\n",
    "                        {\n",
    "                            \"term\": {\n",
    "                                \"job_company_name\": company_name\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        num_records_to_request = 100\n",
    "        params = {\n",
    "            \"dataset\": \"street_address\",\n",
    "            \"query\": json.dumps(ES_QUERY),\n",
    "            \"size\": num_records_to_request,\n",
    "            \"pretty\": True\n",
    "        }\n",
    "        \n",
    "        # Pull all results in multiple batches\n",
    "        batch = 1\n",
    "        all_records = []\n",
    "        start_time = time.time()\n",
    "        while batch == 1 or params[\"scroll_token\"]:\n",
    "            if MAX_NUM_RECORDS != -1:\n",
    "                # Update num_records_to_request\n",
    "                # Compute the number of records left to pull\n",
    "                num_records_to_request = MAX_NUM_RECORDS - len(all_records)\n",
    "                # Clamp this number between 0 and 100\n",
    "                num_records_to_request = max(0, min(num_records_to_request, 100))\n",
    "\n",
    "            if num_records_to_request == 0:\n",
    "                break\n",
    "\n",
    "            params[\"size\"] = num_records_to_request\n",
    "            response = requests.get(PDL_URL, headers=request_header, params=params).json()\n",
    "\n",
    "            if batch == 1:\n",
    "                print(f\"{response['total']} available records in this search\")\n",
    "\n",
    "            all_records.extend(response.get(\"data\", []))\n",
    "            params[\"scroll_token\"] = response.get(\"scroll_token\")\n",
    "            print(f\"Retrieved {len(response.get('data', []))} records in batch {batch}\")\n",
    "            batch += 1\n",
    "\n",
    "            if params[\"scroll_token\"]:\n",
    "                time.sleep(6)   # avoid hitting rate limit thresholds\n",
    "                \n",
    "        end_time = time.time()\n",
    "        runtime = end_time - start_time\n",
    "\n",
    "        print(f\"Successfully recovered {len(all_records)} profiles in \"\n",
    "              f\"{batch} batches [{runtime} seconds]\")\n",
    "        print(\"status:\",response[\"status\"], \"total:\",response[\"total\"])\n",
    "        #there should be a test case to check status and run an error if not 200\n",
    "        \n",
    "        def save_profiles_to_csv(profiles, filename, fields=[], delim=\",\"):\n",
    "            \"\"\"Save profiles to csv (utility function)\"\"\"\n",
    "\n",
    "            # Define header fields\n",
    "            if fields == [] and len(profiles) > 0:\n",
    "                fields = profiles[0].keys()\n",
    "\n",
    "            with open(filename, \"w\", encoding=\"utf-8\") as csvfile:\n",
    "                # Write csv file\n",
    "                writer = csv.writer(csvfile, delimiter=delim)\n",
    "\n",
    "                # Write Header:\n",
    "                writer.writerow(fields)\n",
    "\n",
    "                count = 0\n",
    "                for profile in profiles:\n",
    "                    # Write Body:\n",
    "                    writer.writerow([profile[field] for field in fields])\n",
    "                    count += 1\n",
    "                    print(f\"Wrote {count} lines to: '{filename}'\")\n",
    "        # Use utility function to save profiles to csv\n",
    "        csv_header_fields = ['job_company_location_geo', 'job_company_location_street_address',\n",
    "                                 'job_company_location_address_line_2',\n",
    "                                 'location_street_address', 'location_address_line_2', 'location_geo', 'job_title', 'education']\n",
    "        save_profiles_to_csv(all_records, csv_filename, csv_header_fields)\n",
    "        \n",
    "    df = pd.read_csv(csv_filename)\n",
    "    #turns education array string into array. Extracts school\n",
    "    df[\"education1\"]=df[\"education\"].apply(literal_eval)\n",
    "    def get_school(x):\n",
    "        try:\n",
    "            return x[-1]['school']['name']\n",
    "        except:\n",
    "            return 'null'\n",
    "    df[\"school\"]=df['education1'].apply(get_school)\n",
    "    df = df[df['location_geo'].notnull()]\n",
    "    df['lat'] = df['location_geo'].apply(lambda s: float(s.split(',')[0]))\n",
    "    df['lon'] = df['location_geo'].apply(lambda s: float(s.split(',')[1]))\n",
    "    company_lat=float(df[\"job_company_location_geo\"][0].split(',')[0])\n",
    "    company_lon=float(df[\"job_company_location_geo\"][0].split(',')[1])\n",
    "    company=pd.DataFrame(np.array([[company_lat, company_lon]]), columns=['lat', 'lon'])\n",
    "    # used Mapbox for map with streets\n",
    "    token_name = 'pk.eyJ1IjoidHJhY3ljaGFybGVzMTA4IiwiYSI6ImNsMjJmdmUzajFmeXcza3BkOXgwOWZoNW4ifQ.bFv6klpNU8XWRbEJ0zk1Dw'\n",
    "    px.set_mapbox_access_token(token_name)\n",
    "    fig = px.density_mapbox(df, lat = 'lat', lon = 'lon', zoom=3, mapbox_style='carto-positron', radius = 10, hover_data=['job_title', \"school\"], color_continuous_scale = 'viridis')\n",
    "    fig.add_densitymapbox(lat = [company_lat], lon = [company_lon], colorscale = 'Reds', radius = 15, hovertext = 'company HQ')  \n",
    "\n",
    "    fig.update_layout(margin={\"r\":0, \"t\":0, \"l\":0, \"b\":0})\n",
    "    fig.show()\n",
    "    write_html(fig, company_name + '_employees.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "67ef196b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'total'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14896/2977397718.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(API_KEY, company_name, size)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mFileNotFoundError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '-1_employees.csv'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14896/3993998470.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"a79cd2fea39460c9c8f8c66673d30a34a79c59654050e441b63268dcf28186c3\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14896/2977397718.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(API_KEY, company_name, size)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{response['total']} available records in this search\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[0mall_records\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'total'"
     ]
    }
   ],
   "source": [
    "map(\"a79cd2fea39460c9c8f8c66673d30a34a79c59654050e441b63268dcf28186c3\", \"\", -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66cc40f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14896/938420278.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#turns education array string into array. Extracts school\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"education1\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"education\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mliteral_eval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"school\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"education1\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, arg, na_action)\u001b[0m\n\u001b[0;32m   4159\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4160\u001b[0m         \"\"\"\n\u001b[1;32m-> 4161\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_map_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4162\u001b[0m         return self._constructor(new_values, index=self.index).__finalize__(\n\u001b[0;32m   4163\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"map\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\base.py\u001b[0m in \u001b[0;36m_map_values\u001b[1;34m(self, mapper, na_action)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    869\u001b[0m         \u001b[1;31m# mapper is a function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 870\u001b[1;33m         \u001b[0mnew_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmap_f\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    872\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14896/938420278.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#turns education array string into array. Extracts school\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"education1\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"education\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mliteral_eval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"school\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"education1\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('twitch20_employees.csv')\n",
    "#turns education array string into array. Extracts school\n",
    "df[\"education1\"]=df[\"education\"].apply(literal_eval)\n",
    "df[\"school\"]=df[\"education1\"].map(lambda x: x[''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9eefed07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'palomar college'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['education1'][0][-1]['school']['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f82ebdc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                       palomar college\n",
       "1             the university of michigan: class of 2011\n",
       "2                            louisiana state university\n",
       "3               franklin w. olin college of engineering\n",
       "4                                      tufts university\n",
       "5                           north central state college\n",
       "6                             appleton east high school\n",
       "7                                université de provence\n",
       "8                 southern polytechnic state university\n",
       "9                  university of california, santa cruz\n",
       "10                   tennessee technological university\n",
       "11                           san diego state university\n",
       "12                                university of alberta\n",
       "13                    university of wisconsin - madison\n",
       "14    lev academic center (jct) (jerusalem college o...\n",
       "15         university of illinois at urbana - champaign\n",
       "16                            michigan state university\n",
       "17    university of hawai‘i - shidler college of bus...\n",
       "18                                  syracuse university\n",
       "19                                    towson university\n",
       "Name: education1, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['education1'].apply(lambda x: x[-1]['school']['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9370ad37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20 entries, 0 to 19\n",
      "Data columns (total 9 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   job_company_location_geo             20 non-null     object \n",
      " 1   job_company_location_street_address  20 non-null     object \n",
      " 2   job_company_location_address_line_2  0 non-null      float64\n",
      " 3   location_street_address              20 non-null     object \n",
      " 4   location_address_line_2              8 non-null      object \n",
      " 5   location_geo                         20 non-null     object \n",
      " 6   job_title                            20 non-null     object \n",
      " 7   education                            20 non-null     object \n",
      " 8   education1                           20 non-null     object \n",
      "dtypes: float64(1), object(8)\n",
      "memory usage: 1.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398bb43f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
